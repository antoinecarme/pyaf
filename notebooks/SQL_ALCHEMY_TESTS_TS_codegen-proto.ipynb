{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import AutoForecast as autof\n",
    "import Bench.TS_datasets as tsds\n",
    "#import SignalDecomposition_Perf as tsperf\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "from sqlalchemy import *\n",
    "#from sqlalchemy import desc, nullsfirst\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1 = tsds.load_airline_passengers()\n",
    "df = b1.mPastData\n",
    "\n",
    "\n",
    "def convert_double_to_datetime(x):\n",
    "    ratio = (x - int(x))\n",
    "    fulldate = dt.datetime(int(x), 1, 1, 0, 0, 0)\n",
    "    year_length = dt.datetime(int(x) + 1, 1, 1, 0, 0, 0) - fulldate\n",
    "    fulldate = fulldate + dt.timedelta(days = int(year_length.days*ratio))\n",
    "    return fulldate\n",
    "\n",
    "lDateCol = 'time';\n",
    "df[lDateCol] = df[lDateCol].apply(lambda x : convert_double_to_datetime(x))\n",
    "    \n",
    "lAutoF = autof.cAutoForecast()\n",
    "lAutoF.mOptions.mDebugCycles = True\n",
    "lAutoF\n",
    "\n",
    "lAutoF.train(df , 'time' , 'AirPassengers' , 12)\n",
    "lAutoF.getModelInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trend = lAutoF.mSignalDecomposition.mBestTransformation.mBestModelTrend\n",
    "cycle =  lAutoF.mSignalDecomposition.mBestTransformation.mBestModelCycle\n",
    "ar =  lAutoF.mSignalDecomposition.mBestTransformation.mBestModelAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lSignalName =  lAutoF.mSignalDecomposition.mBestTransformation.mOriginalSignal\n",
    "lTimeName =  lAutoF.mSignalDecomposition.mBestTransformation.mTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cycle.getCycleName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trend.mTrendRidge.coef_ , trend.mTrendRidge.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cycle # NoCycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar.mARRidge.coef_, ar.mARRidge.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lAutoF.mSignalDecomposition.mBestTransformation.mTimeInfo.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlalchemy.__version__\n",
    "sys.setrecursionlimit(200000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in-memory database\n",
    "#lDSN = 'sqlite://'\n",
    "lDSN = 'mysql://user:pass@localhost/GitHubtest'\n",
    "#lDSN = 'postgresql:///GitHubtest'\n",
    "engine = create_engine(lDSN , echo=True)\n",
    "#create_engine(  , echo=True)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.connection.connection.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a= conn.connection.connection.\n",
    "#a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(MetaData.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conn.connection.connection.dsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.engine.has_table('ds1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.engine.dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_sql(\"ds1\" , conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "meta = MetaData()\n",
    "table1 = Table('ds1', meta, autoload=True, autoload_with=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table1.primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exprs = [table1]\n",
    "statement = select(exprs)\n",
    "result = conn.execute(statement).fetchmany(5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lTimeInfo = lAutoF.mSignalDecomposition.mBestTransformation.mTimeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_double_to_datetime(x):\n",
    "    ratio = (x - int(x))\n",
    "    fulldate = datetime.datetime(int(x), 1, 1, 0, 0, 0)\n",
    "    year_length = dt.datetime(int(x) + 1, 1, 1, 0, 0, 0) - fulldate\n",
    "    fulldate = fulldate + datetime.timedelta(days = int(year_length.days*ratio))\n",
    "    return fulldate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ****************************** Signal Transformation CTE **************************************************\n",
    "def addTransformedSignal(table):\n",
    "    exprs = []\n",
    "    trasformed_signal = table.c[lSignalName];\n",
    "    trasformed_signal = trasformed_signal.label(\"Signal\");\n",
    "    # trasformed_time = table.c[lTimeName];\n",
    "    # year1 = func.extract('year' , trasformed_time);\n",
    "    # year1 = func.cast(trasformed_time , Integer);\n",
    "    # ratio = trasformed_time - year1\n",
    "    # date2 = dt.datetime(year1, 7, 11, 12, 47, 28)\n",
    "    # trasformed_time = func.dateadd(func.cast(trasformed_time, bindparam('tomorrow', timedelta(days=1), Interval()))\n",
    "    # trasformed_signal = trasformed_signal.label(\"Time\");\n",
    "    exprs = exprs + [ trasformed_signal ]; # , trasformed_time, year1, ratio, date2]\n",
    "    return exprs\n",
    "\n",
    "signal_exprs = addTransformedSignal(table1) \n",
    "\n",
    "Transformation_CTE = select([table1] + signal_exprs).cte(\"CTE_Transformation\")\n",
    "statement = select([ Transformation_CTE ])\n",
    "result = conn.execute(statement).fetchmany(5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ****************************** Trend Input CTE **************************************************\n",
    "\n",
    "def julian_day(date_expr):\n",
    "    expr_months = extract('year', date_expr) * 12 + extract('month', date_expr) \n",
    "    return expr_months;\n",
    "\n",
    "lAmplitude = lTimeInfo.mTimeMax - lTimeInfo.mTimeMin\n",
    "lAmplitude = lAmplitude.days\n",
    "\n",
    "def addTrendInputs(table , time_col):\n",
    "    exprs = []\n",
    "    row_number_column = func.row_number().over(order_by=asc(table.c[time_col])).label('row_number') - 1\n",
    "    row_number_column = row_number_column.label(\"row_number\")\n",
    "#    normalized_time = func.datediff(text('month'), table.c[time_col] , lTimeInfo.mTimeMin) / func.datediff(text('month'), lTimeInfo.mTimeMax , lTimeInfo.mTimeMin)\n",
    "    normalized_time = (julian_day(table.c[time_col]) - julian_day(lTimeInfo.mTimeMin)) ;\n",
    "    normalized_time = normalized_time / lAmplitude\n",
    "    normalized_time = normalized_time.label(\"normalized_time\")\n",
    "    normalized_time_2 = normalized_time * normalized_time\n",
    "    normalized_time_2 = normalized_time_2.label(\"normalized_time_2\")\n",
    "    normalized_time_3 = normalized_time_2 * normalized_time     \n",
    "    normalized_time_3 = normalized_time_3.label(\"normalized_time_3\")\n",
    "    exprs = exprs + [row_number_column , normalized_time, normalized_time_2, normalized_time_3]\n",
    "    return exprs\n",
    "\n",
    "trend_inputs = addTrendInputs(Transformation_CTE, lTimeInfo.mTime) \n",
    "statement = select(trend_inputs)\n",
    "\n",
    "trend_inputs_CTE = select([Transformation_CTE] + trend_inputs).cte(\"CTE_Trend_Inputs\")\n",
    "statement2 = select([trend_inputs_CTE])\n",
    "\n",
    "result = conn.execute(statement).fetchmany(5)\n",
    "print(result)\n",
    "\n",
    "result2 = conn.execute(statement2).fetchmany(5)\n",
    "print(result2)\n",
    "\n",
    "trend_inputs_df = pd.DataFrame(result2)\n",
    "trend_inputs_df.columns = statement2.columns.keys()\n",
    "trend_inputs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****************************** TREND CTE **********************************\n",
    "\n",
    "def addTrends(table):\n",
    "    exprs = []\n",
    "    trend_expr = table.c[\"normalized_time\"]\n",
    "    print(type(trend_expr))\n",
    "    trend_expr = trend.mTrendRidge.coef_[0] * trend_expr + trend.mTrendRidge.intercept_\n",
    "    trend_expr = trend_expr.label(trend.mOutName);\n",
    "    exprs = exprs + [trend_expr]\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([trend_inputs_CTE]), \"TrendInputAlias\")\n",
    "print(sel1.columns)\n",
    "trends = addTrends(sel1)\n",
    "trend_CTE = select([trend_inputs_CTE] + trends).cte(\"trend_CTE\")\n",
    "statement3 = select([trend_CTE])\n",
    "result3 = conn.execute(statement3).fetchmany(15)\n",
    "trend_df = pd.DataFrame(result3)\n",
    "trend_df.columns = statement3.columns.keys()\n",
    "trend_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ****************************** CYCLE_INPUT CTE **********************************\n",
    "\n",
    "def addCycleInputs(table):\n",
    "    lTime =  lAutoF.mSignalDecomposition.mBestTransformation.mTime\n",
    "    exprs = []\n",
    "    date_expr = table.c[lTime]\n",
    "    date_parts = [extract('year', date_expr).label(lTime + \"_year\") ,  \n",
    "                  extract('month', date_expr).label(lTime + \"_month\") ,  \n",
    "                  extract('day', date_expr).label(lTime + \"_day\") ,  \n",
    "                  extract('hour', date_expr).label(lTime + \"_hour\") ,  \n",
    "                  extract('minute', date_expr).label(lTime + \"_minute\") ,  \n",
    "                  extract('second', date_expr).label(lTime + \"_second\") ,  \n",
    "                  extract('dow', date_expr).label(lTime + \"_dow\") ,  \n",
    "                  extract('week', date_expr).label(lTime + \"_woy\")]\n",
    "    exprs = exprs + date_parts\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([trend_CTE]), \"Trend_CTE1\")\n",
    "print(sel1.columns)\n",
    "cycle_inputs = addCycleInputs(sel1)\n",
    "cycle_input_CTE = select([trend_CTE] + cycle_inputs).cte(\"cycle_input_CTE\")\n",
    "statement3 = select([cycle_input_CTE])\n",
    "result3 = conn.execute(statement3).fetchmany(15)\n",
    "cycle_input_df = pd.DataFrame(result3)\n",
    "cycle_input_df.columns = statement3.columns.keys()\n",
    "cycle_input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****************************** CYCLE CTE **********************************\n",
    "\n",
    "def addCycles(table):\n",
    "    exprs = []\n",
    "    cycle_expr = table.c[\"row_number\"] * 0.0;\n",
    "    cycle_expr = cycle_expr.label(cycle.getCycleName())\n",
    "    exprs = exprs + [cycle_expr]\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([cycle_input_CTE]), \"CycleInputAlias\")\n",
    "print(sel1.columns)\n",
    "cycles = addCycles(sel1)\n",
    "cycle_CTE = select([cycle_input_CTE] + cycles).cte(\"cycle_CTE\")\n",
    "statement3 = select([cycle_CTE])\n",
    "result3 = conn.execute(statement3).fetchmany(15)\n",
    "cycle_df = pd.DataFrame(result3)\n",
    "cycle_df.columns = statement3.columns.keys()\n",
    "cycle_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****************************** CYCLE RESIDUES CTE **********************************\n",
    "\n",
    "def addCycleResidues(table):\n",
    "    exprs = table.columns\n",
    "    lSignalName =  lAutoF.mSignalDecomposition.mBestTransformation.mOriginalSignal\n",
    "    lTimeName =  lAutoF.mSignalDecomposition.mBestTransformation.mTime\n",
    "    cycle_expr = table.c[cycle.getCycleName()];\n",
    "    trend_expr = table.c[trend.mOutName];\n",
    "    cycle_residue_expr = trend_expr + cycle_expr - table.c[lSignalName]\n",
    "    cycle_residue_expr = cycle_residue_expr.label(cycle.getCycleResidueName())\n",
    "    exprs = exprs + [cycle_residue_expr]\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([cycle_CTE]), \"CycleAlias\")\n",
    "print(sel1.columns)\n",
    "cycle_resdiues = addCycleResidues(sel1)\n",
    "cycle_residues_CTE = select(cycle_resdiues).cte(\"cycle_residues_CTE\")\n",
    "statement3 = select([cycle_residues_CTE])\n",
    "result3 = conn.execute(statement3).fetchmany(15)\n",
    "cycle_resdiues_df = pd.DataFrame(result3)\n",
    "cycle_resdiues_df.columns = statement3.columns.keys()\n",
    "cycle_resdiues_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****************************** AR_INPUT CTE **********************************\n",
    "\n",
    "# (select t.\"Signal\"  from ds1 t where ((t.\"index\" + 1) = ds1.\"index\")) as Signal_LAG_1, \n",
    "def createLags(table , H , col, index_col):\n",
    "    TS = table\n",
    "    TS1 = table.alias(\"t\");\n",
    "    col_expr_1 = TS1.c[col];\n",
    "    index_expr = TS.c[index_col]\n",
    "    index_expr_1 = TS1.c[index_col]\n",
    "    exprs = [table];\n",
    "    for h in range(1 , H+1):\n",
    "        expr1 = select([col_expr_1]).where(index_expr == (index_expr_1 + h));\n",
    "        expr = expr1;\n",
    "        expr = expr.label(col + \"_Lag\" + str(h));\n",
    "        exprs = exprs + [expr];\n",
    "    return exprs;\n",
    "\n",
    "def addARInputs(table):\n",
    "    residue_name = cycle.getCycleResidueName();\n",
    "    exprs = createLags(table, \n",
    "                       len(ar.mARLagNames), \n",
    "                       residue_name,\n",
    "                       \"row_number\");\n",
    "    exprs = [table] + exprs\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([cycle_residues_CTE]), \"AR_CTE1\")\n",
    "print(sel1.columns)\n",
    "ar_inputs = addARInputs(sel1)\n",
    "ar_input_CTE = select(ar_inputs).cte(\"ar_input_CTE\")\n",
    "statement3 = select([ar_input_CTE])\n",
    "result3 = conn.execute(statement3).fetchmany(15)\n",
    "ar_input_df = pd.DataFrame(result3)\n",
    "ar_input_df.columns = statement3.columns.keys()\n",
    "ar_input_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****************************** AR CTE **********************************\n",
    "\n",
    "def addARModel(table):\n",
    "    exprs = table.columns\n",
    "    print(ar.mARLagNames)\n",
    "    ar_expr = None;\n",
    "    i = 0 ;\n",
    "    for feat in ar.mARLagNames:\n",
    "        if(ar_expr is None):\n",
    "            ar_expr = ar.mARRidge.coef_[i] * table.c[feat];\n",
    "        else:\n",
    "            ar_expr = ar_expr + ar.mARRidge.coef_[i] * table.c[feat];\n",
    "        i = i + 1;\n",
    "    ar_expr = ar_expr + ar.mARRidge.intercept_;\n",
    "    ar_expr = ar_expr.label(ar.mOutName)\n",
    "    exprs = exprs + [ar_expr]\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([ar_input_CTE]), \"ARInputAlias\")\n",
    "print(sel1.columns)\n",
    "ars = addARModel(sel1)\n",
    "ar_CTE = select(ars).cte(\"ar_CTE\")\n",
    "statement3 = select([ar_CTE])\n",
    "result3 = conn.execute(statement3).fetchall()\n",
    "ar_df = pd.DataFrame(result3)\n",
    "ar_df.columns = statement3.columns.keys()\n",
    "ar_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ****************************** TSMODEL CTE **********************************\n",
    "lModelName =  lAutoF.mSignalDecomposition.mBestTransformation.mBestModelName\n",
    "\n",
    "def add_TS_Model(table):\n",
    "    exprs = table.columns\n",
    "    model_expr = table.c[trend.mOutName] + table.c[cycle.mOutName] + table.c[ar.mOutName];\n",
    "    model_expr = model_expr.label(lModelName)\n",
    "    model_residue = model_expr - table.c[lSignalName]\n",
    "    model_residue = model_residue.label(lModelName + \"Residue\")\n",
    "    exprs = exprs + [model_expr , model_residue]\n",
    "    return exprs\n",
    "\n",
    "sel1 = alias(select([ar_CTE]), \"AR_Alias\")\n",
    "print(sel1.columns)\n",
    "model_vars = add_TS_Model(sel1)\n",
    "model_CTE = select(model_vars).cte(\"model_CTE\")\n",
    "statement3 = select([model_CTE])\n",
    "result3 = conn.execute(statement3).fetchall()\n",
    "model_df = pd.DataFrame(result3)\n",
    "model_df.columns = statement3.columns.keys()\n",
    "model_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "src = StringIO()\n",
    "p = pickle.Pickler(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "favorite_color = { \"lion\": \"yellow\", \"kitty\": \"red\" }\n",
    "pickle.dumps( favorite_color)\n",
    "pickle.dumps(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expr_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expr_columns_cte = [ cte1.c.index, cte1.c.Time, cte1.c.Signal];\n",
    "expr_columns_table2 = [ table2.c.index, table2.c.Time, table2.c.Signal];\n",
    "\n",
    "expr_columns_cte = [ cte1 ];\n",
    "expr_columns_table2 = [ table2 ];\n",
    "\n",
    "def createLagsAsJoins(table , H):\n",
    "    TS = table\n",
    "    join_H = TS;\n",
    "    for h in range(0 , H):\n",
    "        cte_h = select([TS]).cte(\"LAG_\" + str(h + 1))\n",
    "        join_H = join_H.join(cte_h, TS.c.index == (cte_h.c.index + h + 1), isouter=True)\n",
    "    statement = select(join_H.columns).select_from(join_H)\n",
    "    print(join_H.c.keys())\n",
    "    return (statement , join_H)\n",
    "\n",
    "# (select t.\"Signal\"  from ds1 t where ((t.\"index\" + 1) = ds1.\"index\")) as Signal_LAG_1, \n",
    "def createLagsAsCTE(table , H , col, index_col):\n",
    "    TS = table\n",
    "    TS1 = table.alias(\"t\");\n",
    "    col_expr_1 = TS1.c[col];\n",
    "    index_expr = TS.c[index_col]\n",
    "    index_expr_1 = TS1.c[index_col]\n",
    "    exprs = [table];\n",
    "    for h in range(1 , H+1):\n",
    "        expr1 = select([col_expr_1]).where(index_expr == (index_expr_1 + h));\n",
    "        expr = expr1;\n",
    "        expr = expr.label(col + \"_LAG_\" + str(h));\n",
    "        exprs = exprs + [expr];\n",
    "    cte_H = select(exprs).cte(\"LAGS\")\n",
    "    statement = select([cte_H])\n",
    "    print(cte_H.c.keys())\n",
    "    return (statement , cte_H)\n",
    "\n",
    "def addRowNumber(table , time_col):\n",
    "    exprs = [table]\n",
    "    row_number_column = func.row_number().over(order_by=asc(table.c[time_col])).label('row_number')\n",
    "    exprs = exprs + [row_number_column]\n",
    "    statement = select(exprs)\n",
    "    return statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stmt = addRowNumber(table2 , 'Time');\n",
    "result = conn.execute(stmt).fetchmany(5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stmt.columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(stmt , j) = createLagsAsCTE(table2 , 4 , 'Signal' , 'index')\n",
    "result = conn.execute(stmt).fetchmany(5)\n",
    "result\n",
    "stmt.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expr_columns_cte = [ cte1.c.index, cte1.c.Time, cte1.c.Signal];\n",
    "expr_columns_table2 = [ table2.c.index, table2.c.Time, table2.c.Signal];\n",
    "\n",
    "expr_columns_cte = [ cte1 ];\n",
    "expr_columns_table2 = [ table2 ];\n",
    "\n",
    "cte2 = select([table2]).cte(\"CTE2\")\n",
    "cte3 = select([table2]).cte(\"CTE3\")\n",
    "cte4 = select([table2]).cte(\"CTE4\")\n",
    "\n",
    "join1 = table2.join(cte1, table2.c.index == (cte1.c.index + 1), isouter=True)\n",
    "join2 = table2.join(cte2, table2.c.index == (cte2.c.index + 2), isouter=True)\n",
    "join3 = table2.join(cte3, table2.c.index == (cte3.c.index + 3), isouter=True)\n",
    "join4 = table2.join(cte4, table2.c.index == (cte4.c.index + 4), isouter=True)\n",
    "\n",
    "join_1234 = table2.join(cte1, table2.c.index == (cte1.c.index + 1), isouter=True).join(cte2, table2.c.index == (cte2.c.index + 2), isouter=True).join(cte3, table2.c.index == (cte3.c.index + 3), isouter=True).join(cte4, table2.c.index == (cte4.c.index + 4), isouter=True)\n",
    "\n",
    "\n",
    "statement = select(expr_columns_cte + expr_columns_table2).where(table2.c.index == (cte1.c.index - 1))\n",
    "statement = statement.order_by(table2.c.index)\n",
    "\n",
    "statement1 = select([table2, cte1]).select_from(join1)\n",
    "statement2 = select([table2, cte1]).select_from(join2)\n",
    "statement3 = select([table2, cte1]).select_from(join3)\n",
    "statement4 = select([table2, cte1]).select_from(join4)\n",
    "\n",
    "statement1234 = select([table2, cte1, cte2, cte3, cte4]).select_from(join_1234)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "join_1234.c.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(stmt , j) = createLagsAsCTE(table2 , 1 , 'Signal' , 'index')\n",
    "result = conn.execute(stmt).fetchmany(5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stmt.columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func.row_number33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = select([table2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "expr = over(func.row_number(), order_by=table2.c.Time)\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def buildSQLForLAgs(H , table):\n",
    "    lSQL = '\\nWITH \"LAGS_CTE\" AS  \\n(SELECT \\nds1.\"index\" AS \"index\",\\n ds1.\"Time\" AS \"Time\",\\n ds1.\"Signal\" AS \"Signal\",\\n';\n",
    "    for h in range(0 , H):\n",
    "        lSQL = lSQL + '(select t.\"Signal\"  from ds1 t where ((t.\"index\" + ' + str(h + 1) + ') = ds1.\"index\")) as Signal_LAG_' + str(h+1)  \n",
    "        if((h+1) < H):\n",
    "            lSQL = lSQL + ', \\n'\n",
    "    lSQL = lSQL + ' \\nFROM ds1) \\nSELECT \"LAGS_CTE\".*  \\nFROM \"LAGS_CTE\"'; # + table;\n",
    "    return lSQL;\n",
    "\n",
    "#stmt = select([expr])\n",
    "lSQL1 = \"SELECT row_number() OVER (ORDER BY ds1.Time) AS anon_1FROM ds1\"\n",
    "#result1 = conn.execute(lSQL)\n",
    "lSQL2 = \"SELECT ROWID AS anon_1FROM ds1\"\n",
    "\n",
    "lSQL3 = buildSQLForLAgs(7 , 'ds1');\n",
    "result2 = conn.execute(lSQL3).fetchall()\n",
    "#result = conn.execute(stmt).fetchall()\n",
    "result2\n",
    "\n",
    "stmt3 = text(lSQL3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= stmt3.columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = stmt3.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.ctes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stmt = select([table2]).\\\n",
    "            order_by(desc(table2.c.A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import column\n",
    "c_A = table2.c.A\n",
    "c_B = table2.c.B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( c_A + c_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_Sum = c_A + c_B\n",
    "c_Sum2 = c_A + 2 * c_B\n",
    "c_Sum3 = (c_A - 55) / 67\n",
    "c_prev_A = \n",
    "\n",
    "stmt = select([c_A, c_B, c_Sum, c_Sum2, c_Sum3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.fetchmany(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateLinearCombination(iTable, iDict , iIntercept):\n",
    "    stmt_arg = []\n",
    "    sum_1 = None\n",
    "    for k,v in iDict.items():\n",
    "        print(k)\n",
    "        name = iTable.c[k]\n",
    "        stmt_arg = stmt_arg + [name]\n",
    "        if(sum_1 is None):\n",
    "            sum_1 = v * name\n",
    "        else:\n",
    "            sum_1 = sum_1 + v * name\n",
    "    sum_1 = sum_1 + iIntercept\n",
    "    sum_1.label(\"MyScore\")\n",
    "    print(sum_1)\n",
    "    return sum_1\n",
    "\n",
    "def debrief_statement(stmt):\n",
    "    print(stmt)\n",
    "    result = conn.execute(stmt)\n",
    "    print(result.fetchmany(6))\n",
    "    return result\n",
    "\n",
    "def debrief_expression(expr):\n",
    "    print(\"debrief_start\")\n",
    "#    stmt_arg = stmt_arg + [expr]\n",
    "    stmt = select([expr] , use_labels=True)\n",
    "    result = debrief_statement(stmt)\n",
    "    print(\"debrief_end\")\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeffs = {}\n",
    "coeffs['A'] = 3\n",
    "coeffs['B'] = 0.3\n",
    "coeffs['C'] = -3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expr = generateLinearCombination(table2, coeffs, iIntercept=5)\n",
    "res = debrief_expression(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa = expr.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaa.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expr.expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(aa, bb) = expr._orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expr.compile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateCaseWhenDiscrete(iTable, iColumn, iDict , iElseValue):\n",
    "    stmt_arg = []\n",
    "    name = iTable.c[iColumn]\n",
    "    case_1 = None\n",
    "    for k,v in iDict.items():\n",
    "        print(k)\n",
    "        if(case_1 is None):\n",
    "            case_1 = [(name == k , v)]\n",
    "        else:\n",
    "            case_1 = case_1 + [(name == k , v)]\n",
    "    print(case_1)\n",
    "    case_2 = case(case_1 , else_ = iElseValue); \n",
    "    return case_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "mapping[\"S\"] = -1\n",
    "mapping[\"W\"] = 1\n",
    "mapping[\"Z\"] = 0\n",
    "\n",
    "expr = generateCaseWhenDiscrete(table2, \"A\", mapping, iElseValue=5)\n",
    "debrief_expression(expr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateCaseWhenWithSegments(iTable, iColumn, iDict , iElseValue):\n",
    "    stmt_arg = []\n",
    "    name = iTable.c[iColumn]\n",
    "    case_1 = None\n",
    "    for k,v in iDict.items():\n",
    "        print(k)\n",
    "        (a , b) = v\n",
    "        if(b):\n",
    "           expr =  (name <= k)\n",
    "        else:\n",
    "           expr =  (name < k)            \n",
    "        if(case_1 is None):\n",
    "            case_1 = [(expr , a)]\n",
    "        else:\n",
    "            case_1 = case_1 + [(expr , a)]\n",
    "    print(case_1)\n",
    "    case_2 = case(case_1 , else_ = iElseValue); \n",
    "    return case_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "#mapping[None] = (-5 , False)\n",
    "mapping[0.5] = (-1 , False)\n",
    "mapping[1.0] = (1 , False)\n",
    "mapping[2] = (0 , True)\n",
    "\n",
    "expr = generateCaseWhenWithSegments(table2, \"B\", mapping, iElseValue=5)\n",
    "debrief_expression(expr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = expr.value\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "X = np.random.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(X[2:3]))\n",
    "print(clf.predict_proba(X[2:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
