{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import AutoForecast as autof\n",
    "\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def convert_double_to_datetime(x):\n",
    "    ratio = (x - int(x))\n",
    "    fulldate = datetime.datetime(int(x), 1, 1, 0, 0, 0)\n",
    "    year_length = datetime.datetime(int(x) + 1, 1, 1, 0, 0, 0) - fulldate\n",
    "    fulldate = fulldate + datetime.timedelta(days = int(year_length.days*ratio))\n",
    "    return fulldate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examples using the autoforecast public API on some datasets (coming from R). see the link below for more datasets.\n",
    "def analyzeTimeSeriesDataset(filename, horizon):\n",
    "    # filename = AirPassengers.csv\n",
    "    lCSVFile = \"https://raw.githubusercontent.com/antoinecarme/TimeSeriesData/master/R_TSData/\" + filename;\n",
    "    # get the CSV file in a pandas datafrmae\n",
    "    df = pd.read_csv(lCSVFile, sep=r',', engine='python');\n",
    "    # in R_TSDAta , the date column is the first column\n",
    "    lDateCol = df.columns[0];\n",
    "    df[lDateCol] = df[lDateCol].apply(lambda x : convert_double_to_datetime(x))\n",
    "    # length of the time series\n",
    "    lLength = df.shape[0];\n",
    "    # use only the N - H first rows for prediction, predict the H last and compare with actual values\n",
    "    lTrainDataset = df[0:lLength - horizon];\n",
    "    for col in df.columns:\n",
    "        if(col != lDateCol):\n",
    "            # forecast each cloumn separately in ths demo\n",
    "            lSignalCol = col;\n",
    "            # create a model(autoforecast object) ..... handle all the process\n",
    "            lAutoF = autof.cAutoForecast()\n",
    "            # set soem options\n",
    "            lAutoF.mOptions.mEnableSeasonals = True;\n",
    "            #lAutoF.mOptions.enable_slow_mode()\n",
    "            #lAutoF.mOptions.mCycle_Criterion = \"L2\";\n",
    "            #lAutoF.mOptions.mCycle_Criterion_Threshold = 10000.2;\n",
    "            # train the model\n",
    "            lAutoF.train(lTrainDataset , lDateCol , lSignalCol, horizon)\n",
    "            # get some mdoel info\n",
    "            lAutoF.getModelInfo();\n",
    "            # access some advanced info ... for aficionados only!!!\n",
    "            lAutoF.mSignalDecomposition.mBestTransformation.mTimeInfo.mResolution\n",
    "            # define an input dataframe\n",
    "            lInput = lTrainDataset.copy();\n",
    "            #print(lInput.tail())\n",
    "            # output dataframe ('forecast' API call ;)\n",
    "            lOutput = lAutoF.forecast(lInput, horizon);\n",
    "            print(\"Forecast Columns \" , lOutput.columns);\n",
    "            # Here , in the output dataframe, we keep only the data, signal and forecast outputs\n",
    "            lForecastCol = lSignalCol + '_BestModelForecast';\n",
    "            lForecastDataFrame = lOutput[[lDateCol , lSignalCol, lForecastCol]]\n",
    "            print(lForecastDataFrame.info())\n",
    "            # actual values\n",
    "            print(\"Actual : \\n\" , df[[lDateCol , lSignalCol]].tail(horizon).values);\n",
    "            # predcit values\n",
    "            print(\"Predicted : \\n\" , lForecastDataFrame.tail(horizon).values);\n",
    "\n",
    "            # serialize the model as json\n",
    "            print(\"\\n\\n<ModelInfo>\")\n",
    "            print(lAutoF.to_json());\n",
    "            print(\"</ModelInfo>\\n\\n\")\n",
    "\n",
    "            # serialize the forecasts as json\n",
    "            print(\"\\n\\n<Forecast>\")\n",
    "            print(lForecastDataFrame.tail(horizon).to_json(date_format='iso'))\n",
    "            print(\"</Forecast>\\n\\n\")\n",
    "            \n",
    "            # some plots\n",
    "            lAutoF.standrdPlots()\n",
    "            \n",
    "            lActualAndPredictedDF = pd.DataFrame();\n",
    "            lActualAndPredictedDF['Date'] = df[lDateCol];\n",
    "            lActualAndPredictedDF['Signal'] = df[lSignalCol];\n",
    "            lActualAndPredictedDF['Forecast'] = lForecastDataFrame[lForecastCol];\n",
    "            lActualAndPredictedDF['Residue'] = lActualAndPredictedDF['Forecast'] - lActualAndPredictedDF['Signal'];\n",
    "            print(lActualAndPredictedDF.tail(horizon).values)\n",
    "            lActualAndPredictedDF.plot.line('Date', ['Signal', 'Forecast' , 'Residue'], figsize=(32, 16))\n",
    "            \n",
    "    return None;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_TSeries = \"AirPassengers.csv austres.csv beaver1.csv beaver2.csv BJsales.csv co2.csv DM.csv EuStockMarkets.csv \\\n",
    "            fdeaths.csv JohnsonJohnson.csv LakeHuron.csv ldeaths.csv lh.csv lynx.csv mdeaths.csv Nile.csv nottem.csv \\\n",
    "            sunspot.month.csv sunspots.csv sunspot.year.csv treering.csv UKDriverDeaths.csv UKgas.csv USAccDeaths.csv \\\n",
    "            WWWusage.csv\".split();\n",
    "\n",
    "analyzeTimeSeriesDataset(\"AirPassengers.csv\" , 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lCSVFile = \"https://raw.githubusercontent.com/antoinecarme/TimeSeriesData/master/R_TSData/\" + \"AirPassengers.csv\";\n",
    "# df = pd.read_csv(lCSVFile, sep=r',', engine='python');\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# a = df.Index.apply(lambda x : convert_double_to_datetime(x))\n",
    "# a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
